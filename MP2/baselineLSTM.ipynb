{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hotel reviews - Sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import git\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "import re\n",
    "\n",
    "from keras.layers import Embedding, Dense, LSTM, Dropout\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "repo = git.Repo('.', search_parent_directories=True)\n",
    "data = train = pd.read_csv(os.path.join(repo.working_tree_dir, \"MP2\\\\train.txt\"), sep='\\t', header = 0, names = ['sentiment','review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TRUTHFULPOSITIVE</td>\n",
       "      <td>We stayed at the Omni between Christmas and Ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DECEPTIVENEGATIVE</td>\n",
       "      <td>I was REALLY looking forward to a nice relaxin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TRUTHFULNEGATIVE</td>\n",
       "      <td>First let me say, I try not to be too critical...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DECEPTIVENEGATIVE</td>\n",
       "      <td>The Ambassador East Hotel is a terrible place ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DECEPTIVENEGATIVE</td>\n",
       "      <td>I needed a place to stay for a business confer...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           sentiment                                             review\n",
       "0   TRUTHFULPOSITIVE  We stayed at the Omni between Christmas and Ne...\n",
       "1  DECEPTIVENEGATIVE  I was REALLY looking forward to a nice relaxin...\n",
       "2   TRUTHFULNEGATIVE  First let me say, I try not to be too critical...\n",
       "3  DECEPTIVENEGATIVE  The Ambassador East Hotel is a terrible place ...\n",
       "4  DECEPTIVENEGATIVE  I needed a place to stay for a business confer..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1119,)\n",
      "(280,)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(data['review'].values, data['sentiment'].values, test_size=0.2, random_state=42, stratify=data['sentiment'].values)\n",
    "\n",
    "y_train = LabelBinarizer().fit_transform(y_train)\n",
    "y_test = LabelBinarizer().fit_transform(y_test)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenizing text\n",
    "max_vocab = 50000\n",
    "tokenizer = Tokenizer(num_words = max_vocab)\n",
    "tokenizer.fit_on_texts(x_train)\n",
    "\n",
    "#Turning text into sequence\n",
    "x_train_seq = tokenizer.texts_to_sequences(x_train)\n",
    "x_test_seq = tokenizer.texts_to_sequences(x_test)\n",
    "\n",
    "#Padding sequences\n",
    "x_train_seq_pad = pad_sequences(x_train_seq)\n",
    "x_test_seq_pad = pad_sequences(x_test_seq, maxlen = np.array(x_train_seq_pad).shape[1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 784, 20)           1000020   \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 128)               76288     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               16512     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 4)                 516       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,093,336\n",
      "Trainable params: 1,093,336\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential(\n",
    "    [\n",
    "        Embedding(max_vocab + 1, 20, input_length = np.array(x_train_seq_pad).shape[1]),\n",
    "        LSTM(128, dropout = 0.3, recurrent_dropout = 0.3),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(0.3),\n",
    "        Dense(4, activation='softmax')\n",
    "    ]\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "32/32 [==============================] - 37s 1s/step - loss: 1.3870 - accuracy: 0.2522 - val_loss: 1.3841 - val_accuracy: 0.3214\n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 52s 2s/step - loss: 1.3744 - accuracy: 0.3376 - val_loss: 1.3652 - val_accuracy: 0.4018\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - 54s 2s/step - loss: 1.2722 - accuracy: 0.4618 - val_loss: 1.2704 - val_accuracy: 0.3929\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 55s 2s/step - loss: 0.9795 - accuracy: 0.5223 - val_loss: 1.0259 - val_accuracy: 0.5000\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 61s 2s/step - loss: 0.7719 - accuracy: 0.6365 - val_loss: 1.0161 - val_accuracy: 0.4821\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 63s 2s/step - loss: 0.6593 - accuracy: 0.6812 - val_loss: 1.4086 - val_accuracy: 0.4911\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 62s 2s/step - loss: 0.5667 - accuracy: 0.7488 - val_loss: 0.8155 - val_accuracy: 0.6786\n",
      "Epoch 8/10\n",
      "32/32 [==============================] - 64s 2s/step - loss: 0.4418 - accuracy: 0.8252 - val_loss: 0.8653 - val_accuracy: 0.6607\n",
      "Epoch 9/10\n",
      "32/32 [==============================] - 63s 2s/step - loss: 0.3497 - accuracy: 0.8550 - val_loss: 0.9044 - val_accuracy: 0.6786\n",
      "Epoch 10/10\n",
      "32/32 [==============================] - 62s 2s/step - loss: 0.2423 - accuracy: 0.9235 - val_loss: 0.8247 - val_accuracy: 0.6964\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20e7d071940>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "model.fit(x_train_seq_pad, y_train, batch_size = 32, epochs = 10, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.8770999312400818\n",
      "Test accuracy: 0.6964285969734192\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test_seq_pad, y_test, verbose=0)\n",
    "print(\"Test loss:\", score[0])\n",
    "print(\"Test accuracy:\", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "32/32 [==============================] - 65s 2s/step - loss: 1.3875 - accuracy: 0.2413 - val_loss: 1.3853 - val_accuracy: 0.2500\n",
      "Epoch 2/20\n",
      "32/32 [==============================] - 62s 2s/step - loss: 1.3822 - accuracy: 0.3585 - val_loss: 1.3628 - val_accuracy: 0.3839\n",
      "Epoch 3/20\n",
      "32/32 [==============================] - 63s 2s/step - loss: 1.2598 - accuracy: 0.4806 - val_loss: 1.0800 - val_accuracy: 0.3839\n",
      "Epoch 4/20\n",
      "32/32 [==============================] - 61s 2s/step - loss: 0.8627 - accuracy: 0.5889 - val_loss: 0.9426 - val_accuracy: 0.6429\n",
      "Epoch 5/20\n",
      "32/32 [==============================] - 63s 2s/step - loss: 0.6140 - accuracy: 0.7210 - val_loss: 0.7944 - val_accuracy: 0.6786\n",
      "Epoch 6/20\n",
      "32/32 [==============================] - 63s 2s/step - loss: 0.4299 - accuracy: 0.8183 - val_loss: 0.8245 - val_accuracy: 0.6786\n",
      "Epoch 7/20\n",
      "32/32 [==============================] - 60s 2s/step - loss: 0.3316 - accuracy: 0.8848 - val_loss: 0.7910 - val_accuracy: 0.6786\n",
      "Epoch 8/20\n",
      "32/32 [==============================] - 62s 2s/step - loss: 0.2189 - accuracy: 0.9355 - val_loss: 0.7005 - val_accuracy: 0.7500\n",
      "Epoch 9/20\n",
      "32/32 [==============================] - 59s 2s/step - loss: 0.2051 - accuracy: 0.9315 - val_loss: 1.1187 - val_accuracy: 0.6786\n",
      "Epoch 10/20\n",
      "32/32 [==============================] - 57s 2s/step - loss: 0.1531 - accuracy: 0.9464 - val_loss: 0.9209 - val_accuracy: 0.6429\n",
      "Epoch 11/20\n",
      "32/32 [==============================] - 59s 2s/step - loss: 0.1311 - accuracy: 0.9603 - val_loss: 1.0736 - val_accuracy: 0.7143\n",
      "Epoch 12/20\n",
      "32/32 [==============================] - 61s 2s/step - loss: 0.0574 - accuracy: 0.9841 - val_loss: 0.8839 - val_accuracy: 0.7679\n",
      "Epoch 13/20\n",
      "32/32 [==============================] - 58s 2s/step - loss: 0.0433 - accuracy: 0.9881 - val_loss: 1.4196 - val_accuracy: 0.6161\n",
      "Epoch 14/20\n",
      "32/32 [==============================] - 64s 2s/step - loss: 0.0533 - accuracy: 0.9841 - val_loss: 1.0384 - val_accuracy: 0.7054\n",
      "Epoch 15/20\n",
      "32/32 [==============================] - 65s 2s/step - loss: 0.0312 - accuracy: 0.9911 - val_loss: 1.2429 - val_accuracy: 0.6786\n",
      "Epoch 16/20\n",
      "32/32 [==============================] - 60s 2s/step - loss: 0.0348 - accuracy: 0.9921 - val_loss: 1.7391 - val_accuracy: 0.6964\n",
      "Epoch 17/20\n",
      "32/32 [==============================] - 59s 2s/step - loss: 0.1092 - accuracy: 0.9672 - val_loss: 1.2267 - val_accuracy: 0.6964\n",
      "Epoch 18/20\n",
      "32/32 [==============================] - 58s 2s/step - loss: 0.0452 - accuracy: 0.9871 - val_loss: 1.1791 - val_accuracy: 0.6964\n",
      "Epoch 19/20\n",
      "32/32 [==============================] - 59s 2s/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 1.2272 - val_accuracy: 0.7143\n",
      "Epoch 20/20\n",
      "32/32 [==============================] - 57s 2s/step - loss: 0.0100 - accuracy: 0.9960 - val_loss: 1.2711 - val_accuracy: 0.7232\n",
      "Test loss: 1.325403094291687\n",
      "Test accuracy: 0.7107142806053162\n"
     ]
    }
   ],
   "source": [
    "model2 = keras.Sequential(\n",
    "    [\n",
    "        Embedding(max_vocab + 1, 20, input_length = np.array(x_train_seq_pad).shape[1]),\n",
    "        LSTM(128, dropout = 0.3, recurrent_dropout = 0.3),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(0.3),\n",
    "        Dense(4, activation='softmax')\n",
    "    ]\n",
    ")\n",
    "model2.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "model2.fit(x_train_seq_pad, y_train, batch_size = 32, epochs = 20, validation_split=0.1)\n",
    "score = model2.evaluate(x_test_seq_pad, y_test, verbose=0)\n",
    "print(\"Test loss:\", score[0])\n",
    "print(\"Test accuracy:\", score[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
